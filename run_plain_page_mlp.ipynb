{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "import plain_page\n",
    "import load_data\n",
    "import neur_nets\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.2%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./train/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.1%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./train/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "113.5%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./train/MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Extracting ./train/MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./train/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.4%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./train/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./train/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "180.4%/home/davidemazzali/anaconda3/envs/envmlproj1/lib/python3.9/site-packages/torchvision/datasets/mnist.py:335: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /tmp/pip-req-build-62ke9nmn/torch/csrc/utils/tensor_numpy.cpp:143.)\n",
      "  return torch.from_numpy(parsed).view(length, num_rows, num_cols)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./train/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.7%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./test/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.1%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./test/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "56.7%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./test/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./test/MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./test/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.4%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./test/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./test/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "180.4%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./test/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# want cuda? set this to True\n",
    "cuda = False\n",
    "\n",
    "# load needed dataset, normalized with l2 for compliance with ProxSARAH's authors methodology\n",
    "# this gives tensors already\n",
    "train_x, train_y = load_data.load_mnist_train_l2()\n",
    "test_x, test_y = load_data.load_mnist_test_l2()\n",
    "\n",
    "# flatten for compliance with ProxSARAH's authors methodology\n",
    "train_x = torch.flatten(train_x, start_dim=1)\n",
    "test_x = torch.flatten(test_x, start_dim=1)\n",
    "\n",
    "if cuda:\n",
    "    train_x, train_y = train_x.cuda(), train_y.cuda()\n",
    "    test_x, test_y = test_x.cuda(), test_y.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# want cuda? set this to True\n",
    "cuda = False\n",
    "\n",
    "num_hidden_layers = 100 # in compliace with the network used by ProxSARAH's authors\n",
    "num_out_classes = 10\n",
    "\n",
    "# use needed loss function\n",
    "lossfunc = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, 0.33159327507019043, 60000, 2.30449, 0.09340\n",
      "3, 0.7987260818481445, 120488, 2.30398, 0.10270\n",
      "249, 1.9845621585845947, 180512, 2.26488, 0.11350\n",
      "495, 3.191392421722412, 240536, 2.17061, 0.24850\n"
     ]
    }
   ],
   "source": [
    "# instantiate needed NN\n",
    "model = neur_nets.MLP(train_x.size(dim = 1), num_hidden_layers, num_out_classes, cuda)\n",
    "\n",
    "b = len(train_y) # batch size, =n in this case\n",
    "\n",
    "eta = 0.045 # we have \"manually binary searched\" for the best hyper-param\n",
    "T = 5000 # number of iterations\n",
    "\n",
    "print_log = True\n",
    "print_msgs = False\n",
    "file_name_log = None # set this to file name to generate log file\n",
    "\n",
    "# prints iteration number, elapsed time, computed gradients, train loss, test accuracy\n",
    "# the same is logged to file if file_name_log is not None\n",
    "_ = plain_page.train_with_plain_page(train_x, train_y, test_x, test_y, model, lossfunc, T, b, eta, file_name_log, True, print_log, print_msgs, as_sgd = False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8ce64ca77d62604bb7077990a444cb5c66dd6b48d20e4430a2b0cf9fefd028bc"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('envmlproj1': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

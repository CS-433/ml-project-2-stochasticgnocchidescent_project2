{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "import plain_page\n",
    "import load_data\n",
    "import neur_nets\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# want cuda? set this to True\n",
    "cuda = False\n",
    "\n",
    "# load needed dataset, normalized with l2 for compliance with ProxSARAH's authors methodology\n",
    "# this gives tensors already\n",
    "train_x, train_y = load_data.load_mnist_train_l2()\n",
    "test_x, test_y = load_data.load_mnist_test_l2()\n",
    "\n",
    "# flatten for compliance with ProxSARAH's authors methodology\n",
    "train_x = torch.flatten(train_x, start_dim=1)\n",
    "test_x = torch.flatten(test_x, start_dim=1)\n",
    "\n",
    "if cuda:\n",
    "    train_x, train_y = train_x.cuda(), train_y.cuda()\n",
    "    test_x, test_y = test_x.cuda(), test_y.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# want cuda? set this to True\n",
    "cuda = False\n",
    "\n",
    "num_hidden_layers = 100 # in compliace with the network used by ProxSARAH's authors\n",
    "num_out_classes = 10\n",
    "\n",
    "# use needed loss function\n",
    "lossfunc = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'cuda'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_175418/146480581.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# prints iteration number, elapsed time, computed gradients, train loss, test accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# the same is logged to file if file_name_log is not None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplain_page\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_with_plain_page_random_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlossfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_name_log\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_log\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_msgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_sgd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/DATA/Uni/MachineLearning/stochasticgnocchidescent_proj2/ml-project-2-stochasticgnocchidescent_project2/plain_page.py\u001b[0m in \u001b[0;36mtrain_with_plain_page_random_return\u001b[0;34m(x, y, test_x, test_y, neur_net, loss_func, T, b, eta, log_file_name, save_log, print_log, print_msgs, as_sgd)\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcomputed_gradients\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mprev_grads\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msave_log\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mprint_log\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0;31m# make a temporary NN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m             \u001b[0mtemp_nn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneur_nets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMLP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m784\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0;31m# set it weights to be randomly selected from the history of weights of PAGE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'cuda'"
     ]
    }
   ],
   "source": [
    "# instantiate needed NN\n",
    "model = neur_nets.MLP(train_x.size(dim = 1), num_hidden_layers, num_out_classes, cuda)\n",
    "\n",
    "b = len(train_y) # batch size, =n in this case\n",
    "\n",
    "eta = 0.045 # we have \"manually binary searched\" for the best hyper-param\n",
    "T = 1000 # number of iterations\n",
    "\n",
    "print_log = True\n",
    "print_msgs = False\n",
    "file_name_log = None # set this to file name to generate log file\n",
    "\n",
    "# we run the plainest version of PAGE, incorporating random return\n",
    "\n",
    "# prints iteration number, elapsed time, computed gradients, train loss, test accuracy\n",
    "# the same is logged to file if file_name_log is not None\n",
    "_ = plain_page.train_with_plain_page_random_return(train_x, train_y, test_x, test_y, model, lossfunc, T, b, eta, cuda, file_name_log, True, print_log, print_msgs, as_sgd = False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8ce64ca77d62604bb7077990a444cb5c66dd6b48d20e4430a2b0cf9fefd028bc"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('envmlproj1': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
